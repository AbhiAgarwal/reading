### Artificial Intelligence

#### Definitions

- Branch of computer science that deals with intelligent behavior, learning, and adaptation in machines. Research in AI is concerned with producing machines to automate tasks requiring intelligent behavior.
- Artificial intelligence can be described as all of the following
	- A form of intelligence
	- A computer program that performs some intellectual function

#### Big Questions

- David Hilbert: "can all of mathematical reasoning be formalized?"
	- His question was answered by Gödel's incompleteness proof, Turing's machine and Church's Lambda calculus.

#### Outline of Artificial Intelligence

- There are 2 types of Artificial Intelligence:
	- [Weak AI](https://en.wikipedia.org/wiki/Weak_AI): defines non-sentient computer intelligence, typically focused on a narrow task.
		- Siri is a good example of narrow intelligence. Siri operates within a limited pre-defined range, there is no genuine intelligence, no self-awareness, no life despite being a sophisticated example of weak AI.
		-  "Narrow AI could knock out our electric grid, damage nuclear power plants, cause a global-scale economic collapse, misdirect autonomous vehicles and robots..."
		- An artificial intelligence system which is only intended to be applicable on a specific kind of problems (e.g. computer chess) and not intended to display human-like intelligence in general.
	- [Artificial general intelligence (aka strong AI)](https://en.wikipedia.org/wiki/Artificial_general_intelligence): hypothetical artificial intelligence at least as smart as a human.
		- The ability to perform "general intelligent action".
		- Recursive self improvement (aka seed AI) – speculative ability of strong artificial intelligence to reprogram itself to make itself even more intelligent.
		- Technological singularity – theoretical intelligence explosion predicted to occur in the future, at the point in time when artificial intelligence will have progressed to greater-than-human intelligence, radically changing civilization, and perhaps even human nature.
			- Technological singularity is identified to be an existential risk

#### History of Artificial Intelligence

Brief history of how it started - this is 1943 to 1956

- Began in antiquity, with myths, stories and rumors of artificial beings endowed with intelligence or consciousness by master craftsmen.
- As Pamela McCorduck writes, AI began with "an ancient wish to forge the gods."
- The seeds of modern AI were planted by classical philosophers who attempted to describe the process of human thinking as the "mechanical manipulation of symbols".
- A computer is a machine based on the abstract essence of mathematical reasoning.
- Aim of people in the beginning was to "seriously discussing the possibility of building an electronic brain".
- ***KEY MOMENT***: The field of AI research was founded at a conference on the campus of Dartmouth College in the summer of 1956.

Routes of an intelligent mechanical men go far back

- Mechanical men and artificial beings appear in Greek myths, such as the golden robots of Hephaestus and Pygmalion's Galatea.
- In the Middle Ages, there were rumors of secret mystical or alchemical means of placing mind into matter, such as Jābir ibn Hayyān's Takwin, Paracelsus' homunculus and Rabbi Judah Loew's Golem.
- By the 19th century, ideas about artificial men and thinking machines were developed in fiction, as in Mary Shelley's Frankenstein or Karel Čapek's R.U.R. (Rossum's Universal Robots), and speculation, such as Samuel Butler's "Darwin among the Machines." AI has continued to be an important element of science fiction into the present.

People used to believe that Automatons existed within objects.

- Realistic humanoid automatons were built by craftsman from every civilization, including Yan Shi, Hero of Alexandria, Al-Jazari and Wolfgang von Kempelen. 
- The oldest known automatons were the sacred statues of ancient Egypt and Greece. The faithful believed that craftsman had imbued these figures with very real minds, capable of wisdom and emotion—Hermes Trismegistus wrote that "by discovering the true nature of the gods, man has been able to reproduce it."

Formal reasoning - VERY IMPORTANT historically in AI

- "Artificial intelligence is based on the assumption that the process of human thought can be mechanized."
- The study of mechanical—or "formal"—reasoning has a long history.
- Chinese, Indian and Greek philosophers all developed structured methods of formal deduction in the first millennium BCE.
- Their ideas were developed over the centuries by philosophers such as:
	- Aristotle (who gave a formal analysis of the syllogism)
	- Euclid (whose Elements was a model of formal reasoning)
	- al-Khwārizmī (who developed algebra and gave his name to "algorithm")
	- European scholastic philosophers such as William of Ockham and Duns Scotus.
- Majorcan philosopher Ramon Llull (1232–1315) developed several logical machines devoted to the production of knowledge by logical means;
	- Llull described his machines as mechanical entities that could combine basic and undeniable truths by simple logical operations, produced by the machine by mechanical meanings, in such ways as to produce all the possible knowledge.
	- Llull's work had a great influence on Gottfried Leibniz, who redeveloped his ideas.
- In the 17th century, Leibniz, Thomas Hobbes and René Descartes explored the possibility that all rational thought could be made as systematic as algebra or geometry.
	- Hobbes famously wrote in Leviathan: "reason is nothing but reckoning".
	- Leibniz envisioned a universal language of reasoning (his characteristica universalis) which would reduce argumentation to calculation, so that "there would be no more need of disputation between two philosophers than between two accountants. For it would suffice to take their pencils in hand, down to their slates, and to say each other (with a friend as witness, if they liked): Let us calculate."
	- These philosophers had begun to articulate the ***physical symbol system*** hypothesis that would become the guiding faith of AI research.
		- A physical symbol system (also called a formal system) takes physical patterns (symbols), combining them into structures (expressions) and manipulating them (using processes) to produce new expressions.
			- Examples of some physical symbol systems:
				- Formal logic: the symbols are words like "and", "or", "not", "for all x" and so on.
				- Algebra: the symbols are "+", "×", "x", "y", "1", "2", "3", etc. The expressions are equations.
				- A digital computer: the symbols are zeros and ones of computer memory, the processes are the operations of the CPU that change memory.
				- Chess: the symbols are the pieces, the processes are the legal chess moves, the expressions are the positions of all the pieces on the board.
			- The physical symbol system hypothesis claims that both of these are also examples of physical symbol systems:
				- Intelligent human thought: the symbols are encoded in our brains. The expressions are thoughts. The processes are the mental operations of thinking.
				- A running artificial intelligence program: The symbols are data. The expressions are more data. The processes are programs that manipulate the data.
- In the 20th century, the study of mathematical logic provided the essential breakthrough that made artificial intelligence seem plausible.
	- The foundations had been set by such works as Boole's The Laws of Thought and Frege's Begriffsschrift.
- Building on Frege's system, Russell and Whitehead presented a formal treatment of the foundations of mathematics in their masterpiece, the ***Principia Mathematica*** in 1913.
- Inspired by Russell's success, David Hilbert challenged mathematicians of the 1920s and 30s to answer this fundamental question: "can all of mathematical reasoning be formalized?"
	- His question was answered by Gödel's incompleteness proof, Turing's machine and Church's Lambda calculus. Their answer was surprising in two ways.
		1. They proved that there were, in fact, limits to what mathematical logic could accomplish.
		2. Their work suggested that, within these limits, any form of mathematical reasoning could be mechanized. 
	- The Church-Turing thesis implied that a mechanical device, shuffling symbols as simple as 0 and 1, could imitate any conceivable process of mathematical deduction.
	- The key insight was the ***Turing machine***—a simple theoretical construct that captured the essence of abstract symbol manipulation. This invention would inspire a handful of scientists to begin discussing the possibility of thinking machines.

All of these sets of information led to the formation of Computer Science.

- Calculating machines were built in antiquity and improved throughout history by many mathematicians, including (once again) philosopher Gottfried Leibniz.
- In the early 19th century, Charles Babbage designed a programmable computer (the Analytical Engine), although it was never built.
- Ada Lovelace speculated that the machine "might compose elaborate and scientific pieces of music of any degree of complexity or extent".
- The first modern computers were the massive code breaking machines of the Second World War (such as Z3, ENIAC and Colossus).
- The latter two of these machines were based on the theoretical foundation laid by Alan Turing and developed by John von Neumann.

The birth of AI actually happened in 1956. People started the chatter about AI in 1940s, though. The aim was to create an artificial brain.

- In the 1940s and 50s, a handful of scientists from a variety of fields (mathematics, psychology, engineering, economics and political science) began to discuss the possibility of creating an artificial brain. The field of artificial intelligence research was founded as an academic discipline in 1956.

Cybernetics and early neural networks

- The earliest research into thinking machines was inspired by a confluence of ideas that became prevalent in the late 30s, 40s and early 50s.
- Recent research in neurology had shown that the brain was an electrical network of neurons that fired in all-or-nothing pulses. (Recent for 1950s).
- Key events that occured for people to begin to take this seriously:
	- Norbert Wiener's cybernetics described control and stability in electrical networks.
	- Claude Shannon's information theory described digital signals (i.e., all-or-nothing signals).
		- Either on or off
	- Alan Turing's theory of computation showed that any form of computation could be described digitally.
- The close relationship between these ideas suggested that it might be possible to construct an electronic brain.
- Examples of work in this vein includes robots such as W. Grey Walter's turtles and the Johns Hopkins Beast. 
	- These machines did not use computers, digital electronics or symbolic reasoning; they were controlled entirely by analog circuitry.
- Walter Pitts and Warren McCulloch analyzed networks of idealized artificial neurons and showed how they might perform simple logical functions. They were the first to describe what later researchers would call a neural network.
- One of the students inspired by Pitts and McCulloch was a young Marvin Minsky, then a 24-year old graduate student. In 1951 (with Dean Edmonds) he built the first neural net machine, the SNARC.
- Minsky was to become one of the most important leaders and innovators in AI for the next 50 years.

Turing's Test

- In 1950 Alan Turing published a landmark paper in which he speculated about the possibility of creating machines that think.
- He noted that "thinking" is difficult to define and devised his famous Turing Test.
- If a machine could carry on a conversation (over a teleprinter) that was indistinguishable from a conversation with a human being, then it was reasonable to say that the machine was "thinking".
- This simplified version of the problem allowed Turing to argue convincingly that a "thinking machine" was at least plausible and the paper answered all the most common objections to the proposition.
- The Turing Test was the ***first serious proposal in the philosophy of artificial intelligence***.

Game AI

- In 1951, using the Ferranti Mark 1 machine of the University of Manchester, Christopher Strachey wrote a checkers program and Dietrich Prinz wrote one for chess.
- Arthur Samuel's checkers program, developed in the middle 50s and early 60s, eventually achieved sufficient skill to challenge a respectable amateur.
- Game AI would continue to be used as a measure of progress in AI throughout its history.

Symbolic reasoning and the Logic Theorist

- When access to digital computers became possible in the middle fifties, a few scientists instinctively recognized that a machine that could manipulate numbers could also manipulate symbols and that the manipulation of symbols could well be the essence of human thought. This was a new approach to creating thinking machines.
	- Were computers a by-product of research in Artificial Intelligence?
- In 1955, Allen Newell and (future Nobel Laureate) Herbert A. Simon created the "Logic Theorist" (with help from J. C. Shaw). The program would eventually prove 38 of the first 52 theorems in Russell and Whitehead's Principia Mathematica, and find new and more elegant proofs for some.
- Simon said that they had "solved the venerable mind/body problem, explaining how a system composed of matter can have the properties of mind."
	- This was an early statement of the philosophical position John Searle would later call "Strong AI": that machines can contain minds just as human bodies do.

Dartmouth Conference (Introduction of Artificial Intelligence)

- The Dartmouth Conference of 1956 was organized by Marvin Minsky, John McCarthy and two senior scientists: Claude Shannon and Nathan Rochester of IBM.
- The proposal for the conference included this assertion: "every aspect of learning or any other feature of intelligence can be so precisely described that a machine can be made to simulate it".
- The participants included Ray Solomonoff, Oliver Selfridge, Trenchard More, Arthur Samuel, Allen Newell and Herbert A. Simon, all of whom would create important programs during the first decades of AI research.
- At the conference Newell and Simon debuted the "Logic Theorist" and McCarthy persuaded the attendees to accept "Artificial Intelligence" as the name of the field.
- The 1956 Dartmouth conference was the moment that AI gained its name, its mission, its first success and its major players, and is widely considered the birth of AI.

The golden years of AI - this is 1956–1974

- The years after the Dartmouth conference were an era of discovery, of sprinting across new ground. The programs that were developed during this time were, to most people, simply "astonishing": 
	- computers were solving algebra word problems
	- proving theorems in geometry
	- learning to speak English.
- Few at the time would have believed that such "intelligent" behavior by machines was possible at all.
- Researchers expressed an intense optimism in private and in print, predicting that a fully intelligent machine would be built in less than 20 years.
- Government agencies like ARPA poured money into the new field.

The work they did. Firstly: Reasoning as search.

- Many early AI programs used the same basic algorithm. To achieve some goal (like winning a game or proving a theorem), they proceeded step by step towards it (by making a move or a deduction) as if searching through a maze, backtracking whenever they reached a dead end. This paradigm was called "reasoning as search".
- The principal difficulty was that, for many problems, ***the number of possible paths through the "maze" was simply astronomical*** (a situation known as a "combinatorial explosion").
- Researchers would reduce the search space by using heuristics or "rules of thumb" that would eliminate those paths that were unlikely to lead to a solution.
- Newell and Simon tried to capture a general version of this algorithm in a program called the "General Problem Solver".
- Other "searching" programs were able to accomplish impressive tasks like solving problems in geometry and algebra, such as Herbert Gelernter's Geometry Theorem Prover (1958) and SAINT, written by Minsky's student James Slagle (1961).
- Other programs searched through goals and subgoals to plan actions, like the STRIPS system developed at Stanford to control the behavior of their robot Shakey.

Natural language

- An important goal of AI research is to allow computers to communicate in natural languages like English. An early success was Daniel Bobrow's program STUDENT, which could solve high school algebra word problems.
- A semantic net represents concepts (e.g. "house","door") as nodes and relations among concepts (e.g. "has-a") as links between the nodes. 
	- The first AI program to use a semantic net was written by Ross Quillian and the most successful (and controversial) version was Roger Schank's Conceptual dependency theory.
- Joseph Weizenbaum's ELIZA could carry out conversations that were so realistic that users occasionally were fooled into thinking they were communicating with a human being and not a program.
	- But in fact, ELIZA had no idea what she was talking about. She simply gave a canned response or repeated back what was said to her, rephrasing her response with a few grammar rules. ELIZA was the first chatterbot.

Micro-worlds

- In the late 60s, Marvin Minsky and Seymour Papert of the MIT AI Laboratory proposed that AI research should focus on artificially simple situations known as micro-worlds.
- They pointed out that in successful sciences like physics, basic principles were often best understood using simplified models like frictionless planes or perfectly rigid bodies. Much of the research focused on a "blocks world," which consists of colored blocks of various shapes and sizes arrayed on a flat surface.
- This paradigm led to innovative work in machine vision by Gerald Sussman (who led the team), Adolfo Guzman, David Waltz (who invented "constraint propagation"), and especially Patrick Winston.
- At the same time, Minsky and Papert built a robot arm that could stack blocks, bringing the blocks world to life. The crowning achievement of the micro-world program was Terry Winograd's SHRDLU. It could communicate in ordinary English sentences, plan operations and execute them.

The optimism - Predictions made by people

- 1958, H. A. Simon and Allen Newell: "within ten years a digital computer will be the world's chess champion" and "within ten years a digital computer will discover and prove an important new mathematical theorem."
- 1965, H. A. Simon: "machines will be capable, within twenty years, of doing any work a man can do."
- 1967, Marvin Minsky: "Within a generation ... the problem of creating 'artificial intelligence' will substantially be solved."
- 1970, Marvin Minsky (in Life Magazine): "In from three to eight years we will have a machine with the general intelligence of an average human being."

The money

- In June 1963, MIT received a $2.2 million grant from the newly created Advanced Research Projects Agency (later known as DARPA).
- The money was used to fund project MAC which subsumed the "AI Group" founded by Minsky and McCarthy five years earlier. ARPA continued to provide three million dollars a year until the 70.
- ARPA made similar grants to Newell and Simon's program at CMU and to the Stanford AI Project (founded by John McCarthy in 1963).
- Another important AI laboratory was established at Edinburgh University by Donald Michie in 1965.
- These four institutions would continue to be the main centers of AI research (and funding) in academia for many years.
- The money was proffered with few strings attached: J. C. R. Licklider, then the director of ARPA, believed that his organization should "fund people, not projects!" and allowed researchers to pursue whatever directions might interest them.
- This created a freewheeling atmosphere at MIT that gave birth to the hacker culture, but this "hands off" approach would not last.

The first AI winter 1974–1980. 

- In the 70s, AI was subject to critiques and financial setbacks. AI researchers had failed to appreciate the difficulty of the problems they faced.
- Their tremendous optimism had raised expectations impossibly high, and when the promised results failed to materialize, funding for AI disappeared.
- At the same time, the field of connectionism (or neural nets) was shut down almost completely for 10 years by Marvin Minsky's devastating criticism of perceptrons.
- Despite the difficulties with public perception of AI in the late 70s, new ideas were explored in logic programming, commonsense reasoning and many other areas.

The problems

- Limited computer power: There was not enough memory or processing speed to accomplish anything truly useful.
	- Computer Vision: Moravec estimated that simply matching the edge and motion detection capabilities of human retina in real time would require a general-purpose computer capable of 109 operations/second (1000 MIPS) -- million instructions per second.
		- As of 2011, practical computer vision applications require 10,000 to 1,000,000 MIPS. By comparison, the fastest supercomputer in 1976, Cray-1 (retailing at $5 million to $8 million), was only capable of around 80 to 130 MIPS, and a typical desktop computer at the time achieved less than 1 MIPS.
- Intractability and the combinatorial explosion
	-  1972 Richard Karp (building on Stephen Cook's 1971 theorem) showed there are many problems that can probably only be solved in exponential time (in the size of the inputs).
	- Finding optimal solutions to these problems requires unimaginable amounts of computer time except when the problems are trivial.
		- Many of the silly solutions would never work.
- Commonsense knowledge and reasoning
	- 
- Moravec's paradox
- The frame and qualification problems

### Algorithms & Concepts

- [Means-ends analysis](https://en.wikipedia.org/wiki/Means-ends_analysis)
- [Combinatorial explosion](https://en.wikipedia.org/wiki/Combinatorial_explosion)
- [Stanford Research Institute Problem Solver (STRIPS)](https://en.wikipedia.org/wiki/STRIPS)
- [STUDENT](https://en.wikipedia.org/wiki/STUDENT_(computer_program))
- [ELIZA](https://en.wikipedia.org/wiki/ELIZA)
- [Blocks world](https://en.wikipedia.org/wiki/Blocks_world)
- [SHRDLU](https://en.wikipedia.org/wiki/SHRDLU)
- [Connectionism](https://en.wikipedia.org/wiki/Connectionism)
- [Commonsense reasoning](https://en.wikipedia.org/wiki/Commonsense_reasoning)
- [Logic programming](https://en.wikipedia.org/wiki/Logic_programming)

### Philosophy of Artificial Intelligence

- Weak AI hypothesis: the position in philosophy of artificial intelligence that machines can demonstrate intelligence, but do not necessarily have a mind, mental states or consciousness.
- Strong AI: "solved the venerable mind/body problem, explaining how a system composed of matter can have the properties of mind." (Herbert A. Simon)
- Artificial brain
- Philosophical views of artificial consciousness
	- User illusion
- Artificial intelligence and law
- Chinese room
- Cognitive science
	- Artificial consciousness
	- Embodied cognitive science
		- Embodied cognition
- Ethics of artificial intelligence
- Philosophy of the Mind
	- Computational theory of mind
	- Functionalism
- Physical symbol system
- Synthetic intelligence
- Turing Test

#### People in Artificial Intelligence

- Aristotle
- Euclid
- al-Khwārizmī
- Ramon Llull
- Thomas Hobbes
- René Descartes
- Gottfried Leibniz
- [Pamela McCorduck](https://en.wikipedia.org/wiki/Pamela_McCorduck): (1940) Author of a number of books concerning the history and philosophical significance of artificial intelligence, the future of engineering and the role of women and technology.
- Norbert Wiener
- * Marvin Minsky
- John McCarthy (ofcourse)
- Walter Pitts

#### Books/Reading

- [Machines Who Think: 25th anniversary edition - Pamela McCorduck](http://www.pamelamc.com/html/machines_who_think.html)
- ***READ*** [Darwin among the Machines](https://en.wikipedia.org/wiki/Darwin_among_the_Machines)
- [Physical symbol system](https://en.wikipedia.org/wiki/Physical_symbol_system)
- [The Laws of Thought](https://en.wikipedia.org/wiki/The_Laws_of_Thought)
- [Begriffsschrift](https://en.wikipedia.org/wiki/Begriffsschrift)
- [Principia Mathematica](https://en.wikipedia.org/wiki/Principia_Mathematica)
- [Gödel's incompleteness theorems](https://en.wikipedia.org/wiki/G%C3%B6del%27s_incompleteness_theorems)
- [Turing machine](https://en.wikipedia.org/wiki/Turing_machine)
- [Church–Turing thesis](https://en.wikipedia.org/wiki/Church%E2%80%93Turing_thesis)
- [Lambda calculus](https://en.wikipedia.org/wiki/Lambda_calculus)
- [Johns Hopkins Beast](https://en.wikipedia.org/wiki/Johns_Hopkins_Beast)
- [W. Grey Walter's turtles](https://en.wikipedia.org/wiki/Turtle_(robot))
- [Perceptrons](https://en.wikipedia.org/wiki/Perceptrons_(book))
- [The Logic Theory Machine: A Complex Information Processing System](http://shelf1.library.cmu.edu/IMLS/MindModels/logictheorymachine.pdf)

#### Conferences

- [AI@50](https://en.wikipedia.org/wiki/AI@50)

### Sources

- https://en.wikipedia.org/wiki/History_of_artificial_intelligence
- https://en.wikipedia.org/wiki/Outline_of_artificial_intelligence
- https://en.wikipedia.org/wiki/Progress_in_artificial_intelligence
- https://en.wikipedia.org/wiki/Timeline_of_artificial_intelligence
- https://en.wikipedia.org/wiki/History_of_natural_language_processing
- https://en.wikipedia.org/wiki/Philosophy_of_artificial_intelligence